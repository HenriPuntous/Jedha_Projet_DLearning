# -*- coding: utf-8 -*-
"""Yolov5_RDD_DMgt_20Aug_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_cunrZ2GuyHp42Mm7KKNG53eGW1koz9Y

# Setup
"""

#Montage du disque
from google.colab import drive
drive.mount('/content/drive')

"""Clone repo, install dependencies and check PyTorch and GPU."""

# Commented out IPython magic to ensure Python compatibility.
#%cd '/home/utilisateur/VSCode/FullStack/9. Personal project/'
# %pip install wandb
!git clone https://github.com/ultralytics/yolov5  # clone

# Commented out IPython magic to ensure Python compatibility.
# %cd yolov5
# %pip install -qr requirements.txt  # install

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov5

import torch
#import utils
#display = utils.notebook_init()
from IPython.display import Image  # for displaying images
import os 
import random
import shutil
from sklearn.model_selection import train_test_split
import xml.etree.ElementTree as ET
from xml.dom import minidom
from tqdm import tqdm
from PIL import Image, ImageDraw
import numpy as np
import matplotlib.pyplot as plt

random.seed(108)

"""Move to dataset folder"""

#Montage du disque
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %mkdir RoadDamageDataset 
# %cd RoadDamageDataset

# train set
!wget -c https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/IEEE_bigdata_RDD2020/train.tar.gz

# test1 set
#!wget -c https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/IEEE_bigdata_RDD2020/test1.tar.gz

# + test2 set will be released on 10th, September
# test1 set
#!wget -c https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/IEEE_bigdata_RDD2020/test2.tar.gz

!tar xf train.tar.gz
#!tar xf test1.tar.gz
#!tar xf test2.tar.gz

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov5/RoadDamageDataset/train/
# %mkdir annotations 
# %mkdir images

Country = ["Czech", "India", "Japan"]

for c in Country : 
  # Define the source and destination path
  source = "/content/yolov5/RoadDamageDataset/train/" + c + "/annotations/xmls/"
  destination = "/content/yolov5/RoadDamageDataset/train/annotations/"
  
  # code to move the files from sub-folder to main folder.
  files = os.listdir(source)
  for file in files:
    file_name = os.path.join(source, file)
    shutil.move(file_name, destination)

  # Define the source and destination path
  source = "/content/yolov5/RoadDamageDataset/train/" + c + "/images/"
  destination = "/content/yolov5/RoadDamageDataset/train/images/"
  
  # code to move the files from sub-folder to main folder.
  files = os.listdir(source)
  for file in files:
    file_name = os.path.join(source, file)
    shutil.move(file_name, destination)

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/yolov5/RoadDamageDataset/train'

"""# Annotation to YoloV5 format"""

# Function to get the data from XML Annotation
def extract_info_from_xml(xml_file):
    root = ET.parse(xml_file).getroot()
    
    # Initialise the info dict 
    info_dict = {}
    info_dict['bboxes'] = []

    # Parse the XML Tree
    for elem in root:
        # Get the file name 
        if elem.tag == "filename":
            info_dict['filename'] = elem.text
            
        # Get the image size
        elif elem.tag == "size":
            image_size = []
            for subelem in elem:
                image_size.append(int(subelem.text))
            
            info_dict['image_size'] = tuple(image_size)
        
        # Get details of the bounding box 
        elif elem.tag == "object":
            bbox = {}
            for subelem in elem:
                if subelem.tag == "name":
                    bbox["class"] = subelem.text
                    
                elif subelem.tag == "bndbox":
                    for subsubelem in subelem:
                        bbox[subsubelem.tag] = int(subsubelem.text)            
            info_dict['bboxes'].append(bbox)
    
    return info_dict

# Dictionary that maps class names to IDs
from cmath import inf

# Each DXX class corresponds to one road default ;
# DOO/D01 : longitudinal cracks
# D10/D11 : lateral cracks
# D20 : aligator cracks
# D40 : pot hole
# D43/D44 : passage piéton et lignes blanches
# D50 : bouches d'égouts
# D0w0 : others
class_name_to_id_mapping = {"D00": 0,
                            "D01": 0,
                           "D10": 1,
                            "D11": 1,
                           "D20": 2,
                           "D40": 3,
                           "D43": 4,
                            "D44": 4,
                            "D50": 5,
                            "D0w0": 6
                            }

# Convert the info dict to the required yolo format and write it to disk
def convert_to_yolov5(info_dict, path):
    print_buffer = []
    
    # For each bounding box
    for b in info_dict["bboxes"]:
        try:
            class_id = class_name_to_id_mapping[b["class"]]
        except KeyError:
            print("Invalid Class. Must be one from ", class_name_to_id_mapping.keys())
        
        # Transform the bbox co-ordinates as per the format required by YOLO v5
        b_center_x = (b["xmin"] + b["xmax"]) / 2 
        b_center_y = (b["ymin"] + b["ymax"]) / 2
        b_width    = (b["xmax"] - b["xmin"])
        b_height   = (b["ymax"] - b["ymin"])
        
        # Normalise the co-ordinates by the dimensions of the image
        # if len(info_dict['image_size']) == 2:
        #     image_w, image_h = info_dict["image_size"]
        # elif 'India' in info_dict['filename']:
        #     image_c, image_w, image_h = info_dict["image_size"]
        # else:
        #     image_w, image_h, image_c  = info_dict["image_size"]
        image_w = info_dict["image_size"][1]
        image_h = info_dict["image_size"][1]

          
        b_center_x /= image_w 
        b_center_y /= image_h 
        b_width    /= image_w 
        b_height   /= image_h 
        
        #Write the bbox details to the file 
        print_buffer.append("{} {:.3f} {:.3f} {:.3f} {:.3f}".format(class_id, b_center_x, b_center_y, b_width, b_height))
        
    # Name of the file which we have to save 
    save_file_name = os.path.join(path, info_dict["filename"].replace("jpg", "txt"))
    #save_file_name = os.path.join(info_dict["filename"].replace("jpg", "txt"))
    
    # Save the annotation to disk
    print("\n".join(print_buffer), file= open(save_file_name, "w"))

import xml.etree.ElementTree as ElementTree
base_path = '/content/yolov5/RoadDamageDataset/train/'

cls_names = []
total_images = 0
    
file_list = [filename for filename in os.listdir(base_path + '/annotations/') if not filename.startswith('.')]

for file in file_list:

      total_images = total_images + 1
      if file =='.DS_Store':
          pass
      else:
          infile_xml = open(base_path + '/annotations/' +file)
          tree = ElementTree.parse(infile_xml)
          root = tree.getroot()
          for obj in root.iter('object'):
              cls_name = obj.find('name').text
              cls_names.append(cls_name)

print("total")
print("# of images：" + str(total_images))
print("# of labels：" + str(len(cls_names)))

base_path = '/content/yolov5/RoadDamageDataset/train/'

# Get the annotations
annotations = [os.path.join(base_path + '/annotations/', x) for x in os.listdir(base_path + '/annotations/') if x[-3:] == "xml"]
annotations.sort()

# Convert and save the annotations
for ann in tqdm(annotations):
  info_dict = extract_info_from_xml(ann)
  convert_to_yolov5(info_dict, os.path.join(base_path + '/annotations/'))
annotations = [os.path.join(base_path + '/annotations/', x) for x in os.listdir(base_path + '/annotations/') if x[-3:] == "txt"]

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/yolov5/RoadDamageDataset/train'

random.seed(0)

class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))

def plot_bounding_box(image, annotation_list):
    annotations = np.array(annotation_list)
    w, h = image.size
    print(image.size)
    
    plotted_image = ImageDraw.Draw(image)

    transformed_annotations = np.copy(annotations)
    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w
    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h 
    
    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)
    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)
    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]
    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]
    
    for ann in transformed_annotations:
        obj_cls, x0, y0, x1, y1 = ann
        print(x0)
        plotted_image.rectangle(((x0,y0), (x1,y1)))
        
        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])
    
    plt.imshow(np.array(image))
    plt.show()

# Get any random annotation file 
annotation_file = '/content/yolov5/RoadDamageDataset/train/annotations/India_000010.txt'
with open(annotation_file, "r") as file:
    print(annotation_file)
    annotation_list = file.read().split("\n")[:-1]
    annotation_list = [x.split(" ") for x in annotation_list]
    annotation_list = [[float(y) for y in x ] for x in annotation_list]
    print(annotation_list)

#Get the corresponding image file
image_file = annotation_file.replace("annotations", "images").replace("txt", "jpg")
assert os.path.exists(image_file)

#Load the image
image = Image.open(image_file)

#Plot the Bounding Box
plot_bounding_box(image, annotation_list)

# Read images and annotations
base_path = '/content/yolov5/RoadDamageDataset/train/'

images = []
annotations = []

images.append([os.path.join('images', x) for x in os.listdir(os.path.join(base_path + '/images'))])
annotations.append([os.path.join('annotations', x) for x in os.listdir(os.path.join(base_path + '/annotations')) if x[-3:] == "txt"])

images = images[0]
annotations = annotations[0]
images.sort()
annotations.sort()

print(len(images))
# Split the dataset into train-valid-test splits 
train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 2)
val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 2)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov5/RoadDamageDataset/train/

!mkdir images/train images/val images/test annotations/train annotations/val annotations/test

#Utility function to copy images in designated folders
def move_files_to_folder(list_of_files, destination_folder):
    for f in list_of_files:
        try:
            shutil.move(f, destination_folder)
        except:
            print(f)
            assert False

# Move the images splits into their folders
move_files_to_folder(train_images, 'images/train')
move_files_to_folder(val_images, 'images/val/')
move_files_to_folder(test_images, 'images/test/')

# Move the annotations splits into their folders
move_files_to_folder(train_annotations, 'annotations/train/')
move_files_to_folder(val_annotations, 'annotations/val/')
move_files_to_folder(test_annotations, 'annotations/test/')

!wandb login --relogin cdda194a4c0ad4459d965198054dd1e59b8eef65

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov5

!python train.py --hyp hyp.scratch-high.yaml --epochs 1 --data road_damage.yaml --weights yolov5s.pt --cache --project 'RDD - Yolov5' --name 'HP_demo_RDD_1ep'

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive/RDD/yolov5'

from PIL import Image

model_name='/content/drive/MyDrive/RDD/yolov5/RDDYolov5/third_training_5l_100e_scrlow/weights/best.pt'
model = torch.hub.load(os.getcwd(), 'custom', source='local', path = model_name, force_reload = True)
model.conf = 0.2

!pip install gradio

import gradio as gr
def yolo(im, size=732):
    g = (size / max(im.size))  # gain
    im = im.resize((int(x * g) for x in im.size), Image.ANTIALIAS)  # resize

    results = model(im)  # inference
    results.render()  # updates results.imgs with boxes and labels
    return Image.fromarray(results.imgs[0])


inputs = gr.inputs.Image(type='pil', label="Original Image")
outputs = gr.outputs.Image(type="pil", label="Output Image")

title = 'Modèle de détection des fissures sur la route'
description = "Les meilleurs data-scientists du monde se sont réunis pour créer le plus performant des modèles de détection de fissures sur route (lien Paypal en description)"

#examples = ['/content/drive/MyDrive/RDD/LN/yolov5/RDD - Yolov5/4_training_5s_100e_scrlow/weights/image_test/Czech_000002.jpg']
gr.Interface(yolo, inputs, outputs, title=title, description=description, analytics_enabled=False).launch(
    debug=True)